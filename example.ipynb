{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from camera import Camera\n",
    "import structure\n",
    "import processor\n",
    "import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilder geladen\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('../eigenerAnsatz/bildverband2/DJI_0289.JPG')\n",
    "img2 = cv2.imread('../eigenerAnsatz/bildverband2/DJI_0288.JPG')\n",
    "img3 = cv2.imread('../eigenerAnsatz/bildverband2/DJI_0287.JPG')\n",
    "print(\"Bilder geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punkte gefunden\n"
     ]
    }
   ],
   "source": [
    "#pts1, pts2 = features.find_correspondence_points(img1, img2)\n",
    "#print(\"Punkte gefunden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(\n",
    "    cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY), None)\n",
    "kp2, des2 = sift.detectAndCompute(\n",
    "    cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY), None)\n",
    "kp3, des3 = sift.detectAndCompute(\n",
    "    cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY), None)\n",
    "\n",
    "def matchPoints(kp1,des1,kp2,des2):\n",
    "    # Find point matches\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=100)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Apply Lowe's SIFT matching ratio test\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.8 * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    src_pts = np.asarray([kp1[m.queryIdx].pt for m in good])\n",
    "    dst_pts = np.asarray([kp2[m.trainIdx].pt for m in good])\n",
    "\n",
    "    # Constrain matches to fit homography\n",
    "    retval, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 100.0)\n",
    "    mask = mask.ravel()\n",
    "\n",
    "    # We select only inlier points\n",
    "    pts1 = src_pts[mask == 1]\n",
    "    pts2 = dst_pts[mask == 1]\n",
    "    return pts1.T, pts2.T\n",
    "\n",
    "\n",
    "pts1, pts2a = matchPoints(kp1, des1, kp2, des2)\n",
    "\n",
    "pts2b, pts3 = matchPoints(kp1, des1, kp2, des2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "points1 = processor.cart2hom(pts1)\n",
    "points2a = processor.cart2hom(pts2a)\n",
    "\n",
    "points2b = processor.cart2hom(pts2a)\n",
    "points3 = processor.cart2hom(pts3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.82781887e+00, 7.61792803e+00, 8.68769646e+00, ...,\n",
       "        3.98936694e+03, 3.99002026e+03, 3.99109863e+03],\n",
       "       [6.81190308e+02, 9.98320007e+02, 7.18246582e+02, ...,\n",
       "        1.41994214e+03, 2.03552795e+03, 1.17817090e+03],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.wayland: Wayland does not support QWindow::requestActivate()\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].autoscale_view('tight')\n",
    "ax[0].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "ax[0].plot(points1[0], points1[1], 'r.')\n",
    "ax[1].autoscale_view('tight')\n",
    "ax[1].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "ax[1].plot(points2[0], points2[1], 'r.')\n",
    "ax[2].autoscale_view('tight')\n",
    "ax[2].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "ax[2].plot(points2[0], points2[1], 'r.')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.03065e+03, 0.00000e+00, 1.99400e+03],\n",
       "       [0.00000e+00, 3.03065e+03, 1.51700e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height, width, ch = img1.shape\n",
    "intrinsic = np.array([  # for dino\n",
    "    [3030.65, 0, width / 2-6],\n",
    "    [0, 3030.65, height / 2+17],\n",
    "    [0, 0, 1]])\n",
    "intrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed essential matrix: [[-0.03157542 -1.         -0.23135702]\n",
      " [ 0.95870465 -0.01264242 -0.00189078]\n",
      " [ 0.25888847  0.20644202  0.04803392]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate essential matrix with 2d points.\n",
    "# Result will be up to a scale\n",
    "# First, normalize points\n",
    "points1n = np.dot(np.linalg.inv(intrinsic), points1)\n",
    "points2n = np.dot(np.linalg.inv(intrinsic), points2)\n",
    "E = structure.compute_essential_normalized(points1n, points2n)\n",
    "print('Computed essential matrix:', (-E / E[0][1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison to openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02138276, -1.        , -0.31633499],\n",
       "       [ 0.98961303,  0.04504575, -0.21970331],\n",
       "       [ 0.26023036,  0.02401117, -0.05386352]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E2, mask = cv2.findEssentialMat(points1n[:2].T, points2n[:2].T)\n",
    "# E2 = np.linalg.inv(E2)\n",
    "-E2 / E2[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retval, R, t, mask = cv2.recoverPose(\n",
    "    E2, pts1.T, pts2.T, intrinsic)\n",
    "E2,R,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.98023525, -0.04897094,  0.19167862,  0.19881356],\n",
       "        [-0.04587688, -0.88620151, -0.46102299, -0.24938911],\n",
       "        [ 0.19244261, -0.4607046 ,  0.86643933,  0.94777542]]),\n",
       " array([[-0.98023525, -0.04897094,  0.19167862, -0.19881356],\n",
       "        [-0.04587688, -0.88620151, -0.46102299,  0.24938911],\n",
       "        [ 0.19244261, -0.4607046 ,  0.86643933, -0.94777542]]),\n",
       " array([[ 0.97981755, -0.04064291,  0.19571847,  0.19881356],\n",
       "        [ 0.04640084,  0.99861194, -0.02492283, -0.24938911],\n",
       "        [-0.19443387,  0.03350133,  0.98034337,  0.94777542]]),\n",
       " array([[ 0.97981755, -0.04064291,  0.19571847, -0.19881356],\n",
       "        [ 0.04640084,  0.99861194, -0.02492283,  0.24938911],\n",
       "        [-0.19443387,  0.03350133,  0.98034337, -0.94777542]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Given we are at camera 1, calculate the parameters for camera 2\n",
    "# Using the essential matrix returns 4 possible camera paramters\n",
    "P1 = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]])\n",
    "P2s = structure.compute_P_from_essential(E)\n",
    "P2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97981755  0.04640084 -0.19443387 -0.00105049]\n",
      " [-0.04064291  0.99861194  0.03350133 -0.22537157]\n",
      " [ 0.19571847 -0.02492283  0.98034337  0.97427232]]\n"
     ]
    }
   ],
   "source": [
    "ind = -1\n",
    "for i, P2 in enumerate(P2s):\n",
    "    # Find the correct camera parameters\n",
    "    d1 = structure.reconstruct_one_point(\n",
    "        points1n[:, 0], points2n[:, 0], P1, P2)\n",
    "\n",
    "    # Convert P2 from camera view to world view\n",
    "    P2_homogenous = np.linalg.inv(np.vstack([P2, [0, 0, 0, 1]]))\n",
    "    d2 = P2_homogenous[:3, :4] @ d1\n",
    "\n",
    "    if d1[2] > 0 and d2[2] > 0:\n",
    "        ind = i\n",
    "\n",
    "P2 = np.linalg.inv(np.vstack([P2s[ind], [0, 0, 0, 1]]))[:3, :4]\n",
    "print(P2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison to openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97884388, -0.03770837,  0.20110382, -0.21131096],\n",
       "       [ 0.03815494,  0.99927046,  0.0016565 ,  0.18434596],\n",
       "       [-0.20101957,  0.00605165,  0.97956853, -0.9598772 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retval, R, t, mask = cv2.recoverPose(E2,pts1.T,pts2.T,intrinsic)\n",
    "P2inv = np.hstack([R, t])\n",
    "np.linalg.inv(np.vstack([P2inv,[0,0,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00553646, -1.01953347, -1.00409616, ...,  0.87509442,\n",
       "         0.89586751,  0.86850577],\n",
       "       [-0.42699544, -0.27009344, -0.40814642, ..., -0.03954603,\n",
       "         0.23656618, -0.1444281 ],\n",
       "       [ 1.53287928,  1.5548741 ,  1.53279683, ...,  1.33156662,\n",
       "         1.3647532 ,  1.31957639],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tripoints3d = structure.reconstruct_points(points1n, points2n, P1, P2)\n",
    "tripoints3d = structure.linear_triangulation(points1n, points2n, P1, P2)\n",
    "tripoints3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = cv2.triangulatePoints(P1,P2,pts1,pts2)\n",
    "#tripoints3d = processor.hom2cart(tri)\n",
    "tripoints3d = cv2.convertPointsFromHomogeneous(tri.T).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.wayland: Wayland does not support QWindow::requestActivate()\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure()\n",
    "fig.suptitle('3D reconstructed', fontsize=16)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(tripoints3d[0], tripoints3d[1], tripoints3d[2], 'b.')\n",
    "ax.plot([0], [0], [0], 'r.')\n",
    "ax.plot(-P2[0, 3], -P2[1, 3], -P2[2, 3], 'r.')\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('y axis')\n",
    "ax.set_zlabel('z axis')\n",
    "ax.view_init(elev=135, azim=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
